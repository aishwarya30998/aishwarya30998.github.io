**Aishwarya P**

**AI Engineer  
**Phone**:** +1 (203) 534-8915

Email: [aishwarya.ap998@gmail.com](mailto:aishwarya.ap998@gmail.com)

https://github.com/aishwarya30998

https://aishwarya30998.github.io/index.html

https://www.linkedin.com/in/aishwarya-pentyala/

**AI Engineer with 4+ years of experience designing and deploying production-grade Generative AI systems. Strong expertise in agentic workflows, RAG pipelines, prompt engineering, and multi-modal LLM applications using Python, PyTorch, Hugging Face, LangChain, and AWS. Proven ability to build scalable AI platforms using Docker, Kubernetes, and MLOps practices, collaborating cross-functionally to deliver high-impact AI solutions from concept to production.**

**TECHNICAL SKILLS**

|     |     |
| --- | --- |
| AWS Services | EC2, S3, Lambda, Glue, EMR, CloudWatch, Athena, SQS, SNS, CloudTrail, CloudWatch, Sagemaker, Bedrock. |
| Programming | Python, SQL, PyTorch, TensorFlow, Hugging Face, LangChain, LangGraph, FastAPI |
| ML/Gen AI/ Agentic AI | LLMs, Agentic Workflows, Prompt Engineering, Tool Calling, Function Calling, RAG, Vectorization, Embeddings, Multi-modal GenAI, PEFT Fine-Tuning |
| Knowledge systems | Vector Databases, Knowledge Graph Concepts, Graph-based Retrieval (GraphRAG – conceptual), Ontologies (foundational understanding) |
| Data and ML Foundations | Feature Engineering, Model Evaluation, EDA, Scikit-learn, NumPy, Pandas, OpenCV |
| MLops and Deployment | Docker, Kubernetes, CI/CD, MLflow (conceptual), GitHub Actions, AWS ECS, Lambda, SageMaker, Bedrock |
| Methodologies | Waterfall, Agile |
| Development Tools | Vs Code, Cursor, Eclipse, Linux/Mac OS environment, Git. |

**PROJECTS: Data Science and Gen AI**

- built a production-grade RAG system with semantic chunking, vector similarity search using ChromaDB, and LLM generation via HuggingFace. The system achieves 0.85 faithfulness score using RAGAS evaluation. It's fully containerized with Docker and deployed on HuggingFace Spaces with CI/CD via GitHub Actions.
- **LLM Fine-Tuning**: Finetuning **FLANT5 LLM** using Alpaca dataset: Used **Hugging Face Library**, **prompt-based fine-tuning**.
- Refining the FLAN-T5 Language Model (LLM) through prompt-based fine-tuning of Alpaca data.
- Obtained human evaluation differences and **Rouge** **metrics** for the fully fine-tuned **PEFT** models, enabling the model to respond to user queries accurately.
- Developed a chatbot using **Gemini LLM** and a **stream-lit** app to engage in natural and intuitive conversations with an AI-powered **chatbot**.
- Developed **Q&A Chatbot** and Conversational Q&A chatbot using **Lang chain**.
- Developed an **ATS checker application**, useful for checking resume match between job description and resume, used Streamlit for frontend, and Python. The interactive web app enhances user experience with Google's source Large Language Model results.
- Implemented an end-to-end student performance evaluation system with **data ingestion**, **transformation**, **model training**, and **data pipelines** for new predictions. Utilized **MLOps** practices, AWS ECS, EC2, GitHub Actions, Docker, logging, exception handling, CI/CD pipeline, and model monitoring for real-time insights and continuous model improvement.
- **Heart Disease prediction**: Utilized Random Forest and Logistic Regression to predict heart disease based on health measurements and indicators, achieving improved diagnostic accuracy and assisting medical professionals in patient management.

**PROFESSIONAL WORK EXPERIENCE**

**Client: Healthyr, Remote Feb’2025-Present**

**AI Engineer**

**Responsibilities:**

- Responsible for identifying **AI** **use** **cases** within the company platform and integrating them into project workflows to enhance efficiency.
- Developed and deployed Python + Fast API APIs for LLM-based evaluation and backend workflow automation.
- Leveraged large language models (**LLMs**) to summarize and extract valuable information from patient data PDFs, aiding care advocates in their decision-making processes.
- Designed and implemented a **voice assistant** with user-specific knowledge, enabling patients to receive personalized responses to their queries.
- Implemented **AI Agents** with **tool calling and function calling** functionality alongside with preferred LLM.
- Demonstrated proficiency in Serverless Application Model (**SAM**) to interact with AWS environment, including writing and executing lambda functions locally. Developed various lambda functions for seamless interaction between **AWS** **Lambda**, AWS **S3**, and AWS **Bedrock** models.
- Worked on self-hosting **Langfuse** and integrated it into the application code to monitor requests, responses, and billing for model **traces**.
- Accountable for identifying accurate AI models tailored to specific use cases from a list of available options, ensuring optimal performance and alignment with project requirements.
- Worked on web applications by integrating node.js, **react**, **typescript**, and containerized **docker** applications.
- Used **MongoDB** and **MYSQL** for storing structured and semi-structured data for application.

**Client: Vertex Pharmaceuticals, Remote Oct’2024-Feb’2025**

**Data Engineer**

**Responsibilities:**

- Curated and transformed **semi-structured datasets (JSON, XML, Parquet)** to support downstream analytics and AI model consumption.
- Designed scalable **data pipelines** in Snowflake and DBT to support ML feature stores and vectorization workflows.
- Implemented data quality checks and schema governance to ensure **high-quality training and inference datasets**.
- Developed models in DBT Cloud using SQL window functions and **CTEs**, ensuring efficient and reusable transformation logic.
- Leveraged **Jinja** templating to dynamically extract and utilize environmental variables, enabling a configurable and scalable approach to SQL transformations.
- Built and maintained **DBT** seeds for referential tables, facilitating the standardization of records across data sources, eliminating hard coding in SQL, and supporting client reporting requirements.
- Automated deployment pipelines for TST and PROD environments by integrating DBT Cloud with Bitbucket, streamlining the release process and ensuring smooth deployments.
- Extracted and cleaned data in Excel format and loaded it into raw and cleaned tables with appropriate datatypes.
- Extracted and integrated raw data from **AWS** **S3** into Snowflake, transforming it into structured tables in the raw schema and aligning it with logical models.
- Implemented cleansing error **macros** to track and store duplicates and error records in a centralized error table for all tables in the raw schema, improving data quality and auditability.

**ABM Tech LLC July 2024- Sep’ 2024**

**ML Engineer Trainee**

**Responsibilities:**

- Processed and analyzed customer payment behavior to estimate **customer churn rates** using **predictive modeling (Logistic Regression, Decision Trees)**.
- Implemented **fraud detection models** using **Random Forest and Isolation Forest** to flag suspicious transaction patterns and mitigate risks.
- Applied **anomaly detection techniques (K-Means Clustering, Autoencoders)** to identify fraudulent activities in large-scale financial datasets.
- Performed **feature selection & dimensionality reduction** using **Principal Component Analysis (PCA)** to improve model accuracy.
- Implemented **data preprocessing techniques** (Normalization, Standardization) for algorithms like **KNN, XGBoost, and Gradient Boosting**.
- Conducted **hyperparameter tuning using Grid Search and Randomized Search** to optimize machine learning model performance.
- Implemented **data validation and quality checks** using AWS Glue DataBrew to ensure accurate and clean datasets for ML model training.
- Conducted **exploratory data analysis (EDA) and visualization** using **Matplotlib, Seaborn, and Power BI**, providing actionable insights for business decisions.
- Built **customer segmentation models** with **K-Means Clustering**, enabling personalized marketing campaigns and improved customer retention.

**LTI MINDTREE July 2021-Aug 2022**

**Client: GameStop**

**Responsibilities:**

- Analyzing customer data to identify different customer groups and tailor marketing strategies accordingly.
- Used data to determine optimal pricing strategies for different products and situations.
- Analyzing sales data to optimize inventory levels and prevent stockouts. 
- Monitoring user behavior on online platforms to improve user experience through **NewRelic** and **DataDog**. 
- Designed and **optimized ETL pipelines** using **AWS Glue, Lambda, and Step Functions** to automate data ingestion, transformation, and loading.
- Created and managed **AWS Glue Crawlers** to automatically discover and catalog raw data stored in **Amazon S3**.
- Automated **data pipeline monitoring** by integrating **AWS CloudWatch** and **SNS alerts**, reducing downtime and enhancing system reliability.
- Optimized **AWS Lambda functions** for real-time data processing and configured **event-driven triggers** using **S3 events, DynamoDB Streams, and CloudWatch Events**.
- **Analyzed CloudWatch logs and metrics** to proactively detect anomalies, optimize model performance, and ensure data pipeline stability.
- Implemented **data validation and quality checks** using AWS Glue Data Brew to ensure accurate and clean datasets for ML model training.
- Conducted **exploratory data analysis (EDA) and visualization** using **Matplotlib, Seaborn, and Power BI**, providing actionable insights for business decisions.
- Built **customer segmentation models** with **K-Means Clustering**, enabling personalized marketing campaigns and improved customer retention.
- Created **high-level and low-level design documents** for **AWS data pipelines and ML workflows**, ensuring adherence to best practices.

**Mindtree LTD**

**Client: GlobalPay. July2020-June2021**

**Responsibilities:**

- Designed and implemented **fraud detection models** using supervised and unsupervised learning (Logistic Regression, Random Forest, Isolation Forest, Autoencoders) to flag suspicious transactions and reduce false positives.
- Performed **customer segmentation** using clustering techniques (K-Means, DBSCAN) to enable targeted marketing campaigns and improved risk profiling for high-value customers.
- Built **predictive models** for payment default risk and churn forecasting, improving business decision-making for credit and customer retention.
- Conducted **EDA and statistical modeling** on payment and claims datasets to identify patterns in transaction frequency, high-risk geographies, and seasonal behavior.
- Automated **data ingestion and processing pipelines** using Python, SQL, and AWS services (Glue, Lambda, S3) to integrate structured and semi-structured payment records.
- Implemented **real-time monitoring dashboards** with Tableau/Power BI to track fraud alerts, transaction volume, and revenue KPIs.
- Collaborated with cross-functional teams to translate business rules into **data-driven ML solutions**, aligning with compliance and financial regulations.

**Tech Stack:** Python, SQL, Pandas, Scikit-learn, PyTorch, AWS (Glue, S3, Lambda), Power BI, Tableau

**Mindtree LTD**

**Client: Auto-Owners Insurance Co.**

**Role: Data Analyst Oct 2019 – June 2020**

- Developed claims fraud detection models using anomaly detection (Isolation Forest, K-Means clustering) and supervised methods (XGBoost, Random Forest), reducing fraudulent claim payouts.
- Built predictive models for insurance risk scoring and premium optimization, leveraging regression techniques and historical claim data.
- Designed customer churn prediction models, identifying early signals of policy cancellation to support retention campaigns.
- Conducted exploratory data analysis (EDA) on policyholder and claims data, uncovering actionable insights on claim patterns, seasonal risk factors, and customer demographics.
- Automated ETL workflows for ingesting structured/unstructured insurance data (claims, customer profiles, third-party reports) using Python, SQL, and AWS Glue.
- Created interactive dashboards (Power BI, Tableau) for underwriters and leadership, tracking KPIs such as claims ratio, fraud risk, and customer retention trends.
- partnered with cross-functional teams to implement data-driven decision systems, aligning AI models with compliance and business objectives.

**Tech Stack:** Python, Pandas, Scikit-learn, XGBoost, AWS Glue, SQL, Tableau, Power BI

**EDUCATION**

- **University of Bridgeport-Bridgeport, Connecticut** (MS, Artificial Intelligence). Sep’ 2022 – May 2024
- **KL University, India** (Bachelor of Engineering, Computer Science). July 2015 – May 2019